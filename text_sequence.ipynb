{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_sequence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdqo8+Ecrs3YYjVWqPiBnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raqueeb/nlp_bangla/blob/master/text_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyPZfmyDBOyw",
        "colab_type": "text"
      },
      "source": [
        "## 'বাংলা' ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং এ \"টেক্সট থেকে সিকোয়েন্সে\"\n",
        "\n",
        "আমরা গত নোটবুকে একটা বাক্যকে কিভাবে শব্দে টোকেনাইজ করতে হয় সেটা দেখেছিলাম। সেটা আমরা করেছিলাম টেন্সরফ্লো এর কয়েকটি টুল দিয়ে। বিশেষ করে texts_to_sequences মেথড এর ব্যবহার নিয়ে। ![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/seq1.png)\n",
        "\n",
        "ছবি: ওয়ার্ড ইনডেক্স\n",
        "\n",
        "## স্টপওয়ার্ড (বহুল ব্যবহৃত শব্দ), যতিচিহ্নের কি হবে?\n",
        "\n",
        "আমাদের বাক্যে যেহেতু আমরা দুটো জিনিস নিয়ে কাজ করেছিলাম,  সেখানে আমরা যদি আলাদা করে নতুন আরেকটা লাইন ঢুকাই তখন কি হতে পারে? ধরা যাক আমরা নতুন একটা বাক্য এখানে যোগ করতে চাচ্ছি “বইমেলা এলে আমরা প্রচুর বই কিনি”। এর আগের উদাহরণে আমরা বাংলা দাড়ি ব্যাপারটা ফিল্টারে ঢুকিয়েছিলাম তবে এবার আমরা আমরা নতুন করে বলছি না। দেখি এবার আমাদের টোকেনাইজার কি করে? এখানে আমাদের নতুন কর্পাসে যতি চিহ্ন যোগ করলেও টোকেনাইজার আমাদের যতিচিহ্ন ফেলে দিয়েছে। কারণ বাই ডিফল্ট কেরাসে প্রচুর যতিচিহ্ন যোগ করা আছে এখানে। বাংলার জন্য । (দাড়ি) যোগ করে নিতে হবে। সচরাচর বাংলা স্টপ ওয়ার্ড (আমি, আপনি, এবং, ইত্যাদি ...) নিয়ে আলাপ করবো সামনে। এখানে টোকেনাইজারের গেট_কনফিগ দিয়ে সেটা দেখা যাবে। নিচের উদাহরণে দেখুন।\n",
        "\n",
        "## নতুন শব্দগুলোর কি হলো?\n",
        "\n",
        "সবচেয়ে মজার কথা হচ্ছে আমাদের কর্পাসে নতুন শব্দ যোগ হয়েছে নতুন সংখ্যা জোড়া ভ্যালু সহ। তবে আমরা যাই যোগ করি, শুধুমাত্র নতুন ইউনিক শব্দের একটা করে সিকোয়েন্স নম্বর বসবে। \"আমি\" শব্দটা প্রতি বাক্যে আলাদা করে আসলেও কর্পাসে একবারই আসবে।"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBqUseMdA_CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "    'আমি ভালবাসি বই পড়তে,',\n",
        "    'আমি ভালবাসি বই লিখতে!',\n",
        "    'বইমেলা এলে আমি প্রচুর বই কিনি'\n",
        "        ]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYCw5EXgCYj4",
        "colab_type": "text"
      },
      "source": [
        "আগের মতো \"ফিট অন টেক্সট\" করি।"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbeZpO4WCeXl",
        "colab_type": "code",
        "outputId": "16d474e4-f9c4-4596-a108-075a9354be0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'আমি': 1, 'বই': 2, 'ভালবাসি': 3, 'পড়তে': 4, 'লিখতে': 5, 'বইমেলা': 6, 'এলে': 7, 'প্রচুর': 8, 'কিনি': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZc2et6YmwMx",
        "colab_type": "text"
      },
      "source": [
        "এবার যতিচিহ্ন অথবা স্টপওয়ার্ড যেহেতু দেইনি আলাদা করে, দেখি টোকেনাইজার কি করে?\n",
        "\n",
        "দেখুন ফিল্টারে, আগে থেকেই দেয়া আছে এই স্টপওয়ার্ড, মানে যতিচিহ্ন, তবে বাংলা দাড়ি (।) যোগ করে নিতে হবে।\n",
        "\n",
        "`\"filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_{|}~\\t\\n',\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI5YvqIPnS5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bf15e741-8375-4ea1-b447-b0baca425f87"
      },
      "source": [
        "tokenizer.get_config()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'char_level': False,\n",
              " 'document_count': 3,\n",
              " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
              " 'index_docs': '{\"4\": 1, \"3\": 2, \"2\": 3, \"1\": 3, \"5\": 1, \"8\": 1, \"6\": 1, \"7\": 1, \"9\": 1}',\n",
              " 'index_word': '{\"1\": \"\\\\u0986\\\\u09ae\\\\u09bf\", \"2\": \"\\\\u09ac\\\\u0987\", \"3\": \"\\\\u09ad\\\\u09be\\\\u09b2\\\\u09ac\\\\u09be\\\\u09b8\\\\u09bf\", \"4\": \"\\\\u09aa\\\\u09dc\\\\u09a4\\\\u09c7\", \"5\": \"\\\\u09b2\\\\u09bf\\\\u0996\\\\u09a4\\\\u09c7\", \"6\": \"\\\\u09ac\\\\u0987\\\\u09ae\\\\u09c7\\\\u09b2\\\\u09be\", \"7\": \"\\\\u098f\\\\u09b2\\\\u09c7\", \"8\": \"\\\\u09aa\\\\u09cd\\\\u09b0\\\\u099a\\\\u09c1\\\\u09b0\", \"9\": \"\\\\u0995\\\\u09bf\\\\u09a8\\\\u09bf\"}',\n",
              " 'lower': True,\n",
              " 'num_words': 10,\n",
              " 'oov_token': None,\n",
              " 'split': ' ',\n",
              " 'word_counts': '{\"\\\\u0986\\\\u09ae\\\\u09bf\": 3, \"\\\\u09ad\\\\u09be\\\\u09b2\\\\u09ac\\\\u09be\\\\u09b8\\\\u09bf\": 2, \"\\\\u09ac\\\\u0987\": 3, \"\\\\u09aa\\\\u09dc\\\\u09a4\\\\u09c7\": 1, \"\\\\u09b2\\\\u09bf\\\\u0996\\\\u09a4\\\\u09c7\": 1, \"\\\\u09ac\\\\u0987\\\\u09ae\\\\u09c7\\\\u09b2\\\\u09be\": 1, \"\\\\u098f\\\\u09b2\\\\u09c7\": 1, \"\\\\u09aa\\\\u09cd\\\\u09b0\\\\u099a\\\\u09c1\\\\u09b0\": 1, \"\\\\u0995\\\\u09bf\\\\u09a8\\\\u09bf\": 1}',\n",
              " 'word_docs': '{\"\\\\u09aa\\\\u09dc\\\\u09a4\\\\u09c7\": 1, \"\\\\u09ad\\\\u09be\\\\u09b2\\\\u09ac\\\\u09be\\\\u09b8\\\\u09bf\": 2, \"\\\\u09ac\\\\u0987\": 3, \"\\\\u0986\\\\u09ae\\\\u09bf\": 3, \"\\\\u09b2\\\\u09bf\\\\u0996\\\\u09a4\\\\u09c7\": 1, \"\\\\u09aa\\\\u09cd\\\\u09b0\\\\u099a\\\\u09c1\\\\u09b0\": 1, \"\\\\u09ac\\\\u0987\\\\u09ae\\\\u09c7\\\\u09b2\\\\u09be\": 1, \"\\\\u098f\\\\u09b2\\\\u09c7\": 1, \"\\\\u0995\\\\u09bf\\\\u09a8\\\\u09bf\": 1}',\n",
              " 'word_index': '{\"\\\\u0986\\\\u09ae\\\\u09bf\": 1, \"\\\\u09ac\\\\u0987\": 2, \"\\\\u09ad\\\\u09be\\\\u09b2\\\\u09ac\\\\u09be\\\\u09b8\\\\u09bf\": 3, \"\\\\u09aa\\\\u09dc\\\\u09a4\\\\u09c7\": 4, \"\\\\u09b2\\\\u09bf\\\\u0996\\\\u09a4\\\\u09c7\": 5, \"\\\\u09ac\\\\u0987\\\\u09ae\\\\u09c7\\\\u09b2\\\\u09be\": 6, \"\\\\u098f\\\\u09b2\\\\u09c7\": 7, \"\\\\u09aa\\\\u09cd\\\\u09b0\\\\u099a\\\\u09c1\\\\u09b0\": 8, \"\\\\u0995\\\\u09bf\\\\u09a8\\\\u09bf\": 9}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtUdoaqBG8MJ",
        "colab_type": "text"
      },
      "source": [
        "## আচ্ছা, আমরা কি মেপে কথা বলি?\n",
        "\n",
        "কেমন হতো প্রতিটা বাক্যে একটা নির্দিষ্ট শব্দ থাকতো? সেটা কি কখনো হয়? তাহলে নিউরাল নেটওয়ার্ককে কিভাবে কাজ করাবো? আগে আলাপ করেছিলাম - প্যাডিং।\n",
        "\n",
        "## সমস্যাটা দেখি বিভিন্ন লেনথের বাক্যে\n",
        "\n",
        "আমাদের আগের বাক্যে চারটা করে শব্দ ছিল। এখন নতুন একটা বাক্য যোগ করলাম যেখানে ৬টা শব্দ যোগ করা হয়েছে। ইনডেক্সে নতুন বাক্যের ভেতরে ইউনিক শব্দগুলো বাদ দিয়ে বাকি শব্দগুলোকে নতুন করে জোড়া ‘কি-ভ্যালু’ দিয়ে দিয়েছে। এটা একটা নতুন ওয়ার্ড ভ্যালু ইনডেক্স যোগ করল কর্পাসে। দেখতে পাচ্ছেন তো ছবিতে?\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/raqueeb/nlp_bangla/master/assets/seq2.png)\n",
        "\n",
        "ছবি: নতুন ওয়ার্ড ইনডেক্স তৈরি হয়েছে কর্পাসে\n",
        "\n",
        "এখানে আমরা একটা বাক্যে বিভিন্ন শব্দ দিয়ে যে ডিকশনারি তৈরি করলাম সেটাকে কর্পাস হিসেবে ব্যবহার করছি। এতক্ষণ আমরা যা খেলেছি সেগুলো হচ্ছে শব্দকে এনকোড করা। এখন আমরা আমাদের বাক্যগুলোকে একটা লিস্টে ভাগ করব যেখানে টোকেনগুলোকে পাশাপাশি দেখা যাবে। এরপর টোকেনগুলোকে কিভাবে এদিক ওদিক করা যায় সেটা দেখবো আমরা।\n",
        "\n",
        "এখানে একটা মজার ধারণা নিয়ে আলাপ করি।\n",
        "\n",
        "## প্যাডিং, একই লেনথ এর বাক্য?\n",
        "\n",
        "আমরা এ পর্যন্ত যতগুলো বাক্য বলেছি তার মধ্যে দুটো বাক্য চারটা শব্দের আর একটা বাক্য ছয়টা শব্দের। আমরা যখন কোন নিউরাল নেটওয়ার্ক কিছু ফিট করতে চাই তখন সবকিছুই একি লেংথ বা সাইজ করে পাঠাই। মনে আছে আমরা ইমেজ নিয়ে কিভাবে কাজ করেছিলাম?  আমাদের ইনপুট লেয়ারে যখন প্রতিটা ইমেজ ফিড করছিলাম নিউরাল নেটওয়ার্ক সেখানে যদি ইমেজগুলো আলাদা সাইজের হতো সেগুলো কে প্রথমে আমরা রিসাইজ করে নিতাম  এক সাইজে। আমরা যখন টেক্সট নিয়ে কাজ করব তখন আমরা কখনোই বলতে পারব না একটা বাক্যে কতগুলো শব্দ হতে পারে এবং সেগুলোর সংখ্যা অনেকটাই অজানা থাকবে একটা নিউরাল নেটওয়ার্কের জন্য। \n",
        "\n",
        "গতবছর আমি scikit-learn দিয়ে ন্যাচারাল ল্যাংগুয়েজ প্রসেসিং ব্যাপারটা শুরু করলেও সেটাকে পরে বন্ধ করে টেন্সরফ্লো দিয়ে শুরু করেছিলাম।  তারপর পেছনে আর ফিরে তাকাতে হয়নি।  টেন্সরফ্লো ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং এর জন্য অনেকগুলো এপিআই তৈরি করে দিয়েছে যা সাধারণ পাইথন এবং scikit-learn দিয়ে ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং থেকে অনেক কষ্ট কমিয়ে নিয়ে এসেছে।  এর আগে আমরা এই জিনিসটার কিছুটা কাজ দেখেছি টেন্সরফ্লো দিয়ে।  আমরা যেহেতু সিকুয়েন্সের একটা লিস্ট ধরে কাজ শুরু করেছিলাম,  সেখানে বাক্যগুলোকে টোকেন দিয়ে এনকোড করে তার পাশাপাশি দরকারি কোড কোথায় কোথায় কিভাবে কাজ করছে সেটাও দেখেছি আগে। \n",
        "\n",
        "যেহেতু আমরা আরেকটা বাক্য যোগ করেছি আমাদের আগের বাক্যের লিস্ট এ,  সেখানে আগের দুটো বাক্যে চারটা শব্দ আর পরের বাক্যে আমরা ছয় শব্দ সহ নতুন বাক্য যোগ করেছিলাম। \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hq83aorjIS5",
        "colab_type": "text"
      },
      "source": [
        "## ৪টা বিভিন্ন লেনথের বাক্য দিয়ে কর্পাস\n",
        "\n",
        "এখন আমরা দেখতে চাইবো এরকম ভিন্ন ভিন্ন শব্দ সম্বলিত বাক্য গুলোকে কিভাবে আমরা নিউরাল নেটওয়ার্ক পাঠাবো?  আগের ইমেজের মত বলতে গেলে এখানেও আমরা একটা বাক্যে সর্বোচ্চ কতগুলো শব্দ হতে পারে তার পাশাপাশি ছোট শব্দ গুলোকে কিভাবে গোঁজামিল দিয়ে বড় শব্দ বানাবো সেটাই দেখব সামনে। \n",
        "\n",
        "ছোটবেলায় ক্যাডেট কলেজে যখন আমাদেরকে জুতা বানিয়ে দিত,  তখন আমরা ভাবতাম যাতে আমাদের জুতোগুলো একটু বড় থাকে।  কারণ  জুতো ছোট হলে পড়তে কষ্ট, তবে বড় হলে সমস্যা কম কারণ জুতোর ভেতরে কাপড়ের প্যাডিং দিয়ে বড় জুতা কে পড়া যায় সহজে।  জুতো বড় হলে সেখানে একটা মোজার জায়গায় দুটো পড়ে সেই কাজটা চালানো যেত সহজে। \n",
        "\n",
        "এবার আমরা চেষ্টা করব দ্বিতীয় পর্যায়ে যেতে। এখানে texts_to_sequences মেথড দিয়ে আমরা একটা বাক্য থেকে সংখ্যার একটা সিকুয়েন্স তৈরি করব যাতে একটা নিউরাল নেটওয়ার্ককে ঠিকমতো শেখাতে পারে। এখানে এমন একটা টুল ব্যবহার করব যাতে সে এই প্রসেসে সংখ্যার একটা সিকোয়েন্স এর লিস্ট তৈরি করতে পারে। আমাদের এই প্যাটার্ন স্পটিংটা খুব মজার।\n",
        "\n",
        "এই একই জিনিস ঘটবে আমাদের ছোট ছোট বাক্যের জন্য।  আমরা ধরে নিবো একটা বাক্য কত লম্বা হতে পারে।  এর পাশাপাশি আমরা ছোট ছোট বাক্যগুলোকে শূন্য দিয়ে প্যাডিং করে বড় বাক্য বানাবো যাতে  নিউরাল নেটওয়ার্ক সবসময় একই লম্বার বাক্য পায়। চলুন আমরা দেখে আসি আমাদের নতুন কোড,  যেখানে আমরা টোকেনাইজার ব্যবহার করব যাতে আমাদের বাক্যগুলোকে সিকোয়েন্সে পাল্টে দিতে পারে।  আমরা বলতে পারি একেকটা বাক্যের জন্য একেকটা সিকোয়েন্স,  এবং সেখানে প্রতিটা বাক্য একটা লিস্ট হিসেবে আউটপুটে আসবে। সেই লিস্টে শব্দগুলোকে ইন্টেজারে কনভার্ট হয়ে আসবে এখানে। এখানে উদাহরণে দেখি।\n",
        "\n",
        "পাশাপাশি প্যাডিং এর উদাহরণ দেখবো সামনে।"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gjCYVmSZTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\n",
        "    'আমি ভালবাসি বই পড়তে,',\n",
        "    'আমি ভালবাসি বই লিখতে!',\n",
        "    'বইমেলা এলে আমি প্রচুর বই কিনি',\n",
        "    'এইবার বইমেলায় আমার সাথে তুমি কি যাবে?'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF00HP2MCe0z",
        "colab_type": "code",
        "outputId": "194a6766-f8a4-4c12-c27a-e761d813d0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(\"\\nওয়ার্ড ইনডেক্স = \" , word_index)\n",
        "print(\"\\nসিকোয়েন্স = \" , sequences)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ওয়ার্ড ইনডেক্স =  {'আমি': 1, 'বই': 2, 'ভালবাসি': 3, 'পড়তে': 4, 'লিখতে': 5, 'বইমেলা': 6, 'এলে': 7, 'প্রচুর': 8, 'কিনি': 9, 'এইবার': 10, 'বইমেলায়': 11, 'আমার': 12, 'সাথে': 13, 'তুমি': 14, 'কি': 15, 'যাবে': 16}\n",
            "\n",
            "সিকোয়েন্স =  [[1, 3, 2, 4], [1, 3, 2, 5], [6, 7, 1, 8, 2, 9], [10, 11, 12, 13, 14, 15, 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYD2KJfqU57N",
        "colab_type": "text"
      },
      "source": [
        "টোকেনাইজারের texts_to_sequences মেথড আগের এবং পরের সব শব্দগুলোকে যোগ করেছে নতুন ওয়ার্ড এবং সংখ্যা ভ্যালু জোড়া ডিকশনারিতে। এখানে নতুন দুটো ৭ এবং ৮ শব্দের বাক্য যোগ করেছি কর্পাসে।\n",
        "\n",
        "![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/index2.png)\n",
        "\n",
        "চিত্র: ওয়ার্ড ইনডেক্স এবং সিকোয়েন্সের যোগসুত্র\n",
        "\n",
        "আমাদের নতুন কর্পাসে আগের যেই শব্দগুলো ছিল তার সাথে নতুন দুটো বাক্যের শুধুমাত্র নতুন শব্দগুলো যোগ হয়েছে পরে। আমাদের এখানে ওয়ার্ড ইন্ডেক্স এবং সিক্যুয়েন্স এই দুটোর মধ্যে সংযোগ সূত্র হিসেবে যে শব্দগুলো বারবার ব্যবহার করা হয়েছে সেগুলো চলে গেছে উপরে।  এর পাশাপাশি নতুন বাক্য থেকে যে শব্দগুলো নতুন এসেছে সেগুলো এসে যোগ হয়েছে ডিকশনারিতে নিচের দিকে।  এখানে একটা কথা বলে রাখা ভালো আমাদের চারপাশে আমরা যে শব্দ গুলোকে ব্যবহার করছি সেখানে মেশিন লার্নিং শুধুমাত্র এই কর্পাস এর ভেতরের শব্দ গুলোকে চিনে।  তার বাইরের কোনো শব্দ দিয়ে যদি আমরা টেস্ট করি তাহলে সেই শব্দগুলোকে সে চিনতে পারবে না।  এটাই তো স্বাভাবিক তাই না?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S26-02VuxFt0",
        "colab_type": "text"
      },
      "source": [
        "## সব বাক্যকে এক কাতারে নিয়ে আসা\n",
        "\n",
        "প্যাডিং নিয়ে উদাহরণ দিয়ে কথা বলি বরং। আমরা যখন কথা বলি তখন মেপে মেপে কি কথা বলা যায়? অথবা যখন একটা গল্প লিখছি, সেখানে বাক্যের মধ্যে শব্দ হচ্ছে একটা ভ্যারিয়েবল জিনিস। গুরুত্বের সাথে বাড়ে কমে। এদিকে নিউরাল নেটওয়ার্কের কাজ হচ্ছে সবকিছুই একই সাইজে তার পাওয়া চাই। ইমেজ নিয়ে কাজ করতে গিয়ে দেখেছি - যেই সাইজের ইমেজ হোক না কেন, সেটাকে একই পিক্সেলে নিয়ে আসতাম নিউরাল নেটওয়ার্কে ফিড করার আগে। প্রি-প্রসেসিংয়ে। \n",
        "\n",
        "ভাষা অবশ্যই একটা বিশেষায়িত জিনিস,  আর সে কারণেই আমাদেরকে এখানে বিশেষায়িত কাজ করতে হবে।  এরকম কি হতে পারে আমরা একটা বাক্যে ২০টা শব্দের বেশি ব্যবহার করি? আমার মনে হয় করি, বিশেষ করে যখন লিখি। মেশিন লার্নিং মডেলের জন্য আমরা ধরে নিতে পারি একটা বাক্যে ৮০টার বেশি শব্দ সচরাচর আসবেনা।\n",
        "\n",
        "সেখানে যেহেতু আমরা উদাহরণে মাত্র চারটা বাক্য নিয়ে আলাপ করছি, আমাদের দেখা মতে চারটা বাক্যের মধ্যে শেষের বাক্যে সর্বোচ্চ শব্দ সংখ্যা হচ্ছে ৭।  এখানে আমরা যদি বাক্যের সর্বোচ্চ সিকোয়েন্স ৭ দিয়ে দেই, তাহলে শব্দের ছোট বাক্যগুলোকে আমরা অন্য কিছু দিয়ে প্যাডিং মানে গোজামিল দিতে পারি। এরপর মেশিন ফেলে দেবে গোজামিল মানে বাড়তি প্যাডিং অংশ।\n",
        "\n",
        "প্যাডিং নিয়ে কাজ করতে tensorflow.keras.preprocessing.sequence থেকে আমরা pad_sequences মেথডকে ইমপোর্ট করে নেব আমাদের বের করা সিকোয়েন্সকে প্যাডিং করে নিতে। এখানে দুটো আউটপুট দেখুন। শুরুতে শুধুমাত্র সিকোয়েন্স, এরপরে সেই সিকোয়েন্সের প্যাডিং। শব্দ সংখ্যা - যেহেতু এখানে সর্বোচ্চ maxlen=7, মানে ৭টা শব্দ। আচ্ছা, কি দিয়ে প্যাডিং দেয়া যায়? '০' দিয়ে প্যাডিং দেয়া সিকোয়েন্স বোঝা যাবে সহজে।\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_BugO0SxMZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "1b2602cc-f34e-4bda-ed32-6ff8eff453d4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=7)\n",
        "print(\"ওয়ার্ড ইনডেক্স = \" , word_index)\n",
        "print(\"\\nসিকোয়েন্স = \" , sequences)\n",
        "print(\"\\n'০' দিয়ে প্যাডিং দেয়া সিকোয়েন্স:\")\n",
        "print(padded)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ওয়ার্ড ইনডেক্স =  {'আমি': 1, 'বই': 2, 'ভালবাসি': 3, 'পড়তে': 4, 'লিখতে': 5, 'বইমেলা': 6, 'এলে': 7, 'প্রচুর': 8, 'কিনি': 9, 'এইবার': 10, 'বইমেলায়': 11, 'আমার': 12, 'সাথে': 13, 'তুমি': 14, 'কি': 15, 'যাবে': 16}\n",
            "\n",
            "সিকোয়েন্স =  [[1, 3, 2, 4], [1, 3, 2, 5], [6, 7, 1, 8, 2, 9], [10, 11, 12, 13, 14, 15, 16]]\n",
            "\n",
            "'০' দিয়ে প্যাডিং দেয়া সিকোয়েন্স:\n",
            "[[ 0  0  0  1  3  2  4]\n",
            " [ 0  0  0  1  3  2  5]\n",
            " [ 0  6  7  1  8  2  9]\n",
            " [10 11 12 13 14 15 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0mevgVaUhRn",
        "colab_type": "text"
      },
      "source": [
        "## কি হবে, যখন ওয়ার্ড ইনডেক্সে শব্দটা থাকবে না?\n",
        "\n",
        "আমরা যদি একটা নিউরাল নেটওয়ার্ক কে একটা নির্দিষ্ট কর পাশের টেক্সট মানে শব্দ এবং তার সেখান থেকে জেনারেটেড ওয়ার্ড ইন্ডেক্স  কে ট্রেইন করি তাহলে আমরা সেই ট্রেনিং মডেল থেকে একটা ইনফারেন্ট ব্যবহার করতে পারব।  এর অর্থ হচ্ছে আমাদেরকে সেই একই ওয়ার্ড ইন্ডেক্স এর উপর ইনফার করতে হবে যাকে আমরা সেই একই শব্দ দিয়ে ট্রেনিং করিয়েছিলাম।এর ব্যত্যয় হলে আমাদের কাজের কোন আউটপুট থাকবে না।  আমরা যে কর পাশ দিয়ে নিউরাল নেটওয়ার্ককে  ট্রেইন করাবো এর বাহিরে যদি কোন শব্দ আসে টেস্ট ডাটা সেটে তাহলে তো সে সেটার আউটকামস দিতে পারবে না। নিচে আমাদের নতুন দুটো বাক্য স্টেশন হিসেবে চালিয়ে দেখি।  আপনারা দেখতে পাচ্ছেন এখানে কিছু কিছু শব্দ আমাদের কর পাশে আছে তবে কিছু শব্দ আমাদের আগের কর্পাস এবং ওয়ার্ড ইনডেক্সে ছিলনা,  তাহলে এখন কি হবে?এখানে আমাদের ওয়ার্ড ইনডেক্স এবং সিক্যুয়েন্স দুটো দেখি।  আপনি বলুন এখানে কি কি মিসিং আছে অথবা কেন মিসিং আছে? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5At652ZlU-RQ",
        "colab_type": "code",
        "outputId": "30ea85c2-af4f-438c-d84f-3c06debb3f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# আমরা নতুন কিছু শব্দ ব্যবহার করি যেটা আমাদের টোকেনাইজারকে ফিট করা হয়নি\n",
        "test_data = [\n",
        "    'আমি আসলেই ভালবাসি বই পড়তে',\n",
        "    'বইমেলায় এবার প্রচুর নতুন বই এসেছে!'\n",
        "]\n",
        "\n",
        "# texts_to_sequences কি বের করে দেখি\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"টেস্ট সিকোয়েন্স = \", test_seq)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "টেস্ট সিকোয়েন্স =  [[1, 3, 2, 4], [11, 8, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05SWR3C7WSbs",
        "colab_type": "text"
      },
      "source": [
        "ওমা, কি হলো ব্যাপারটা? কিছু কিছু শব্দ হারিয়ে গেছে ওয়ার্ড ইনডেক্স এ না থাকার কারণে। কেন হলো এটা?\n",
        "\n",
        "![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/index3.png)\n",
        "\n",
        "এর অর্থ হচ্ছে \n",
        "\n",
        "১. প্রথম বাক্য: 'আমি ভালবাসি বই পড়তে', **আসলেই** মিসিং\n",
        "\n",
        "২. পরের বাক্যে: 'বইমেলায় প্রচুর বই', **এবার, নতুন, এসেছে** মিসিং।\n",
        "\n",
        "এটা থেকে বাঁচার উপায় কি? তারমানে একটা ভাষায় সব শব্দকে আনতে হবে আমাদের ওয়ার্ড ইনডেক্সে?\n",
        "\n",
        "কি বলে এটা?\n",
        "\n",
        "এটা সম্ভব?"
      ]
    }
  ]
}