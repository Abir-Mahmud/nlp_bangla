{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_sequence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYnmxEJ+h1tdtjaXZuKiQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raqueeb/nlp_bangla/blob/master/text_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyPZfmyDBOyw",
        "colab_type": "text"
      },
      "source": [
        "## 'বাংলা' ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং এ \"টেক্সট থেকে সিকোয়েন্সে\"\n",
        "\n",
        "আমরা গত নোটবুকে একটা বাক্যকে কিভাবে শব্দে টোকেনাইজ করতে হয় সেটা দেখেছিলাম। সেটা আমরা করেছিলাম টেন্সরফ্লো এর কয়েকটি টুল দিয়ে। ![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/seq1.png)\n",
        "\n",
        "ছবি: ওয়ার্ড ইনডেক্স\n",
        "\n",
        "## স্টপওয়ার্ড, যতিচিহ্নের কি হবে?\n",
        "\n",
        "আমাদের বাক্যে যেহেতু আমরা দুটো জিনিস নিয়ে কাজ করেছিলাম,  সেখানে আমরা যদি আলাদা করে নতুন আরেকটা লাইন ঢুকাই তখন কি হতে পারে? ধরা যাক আমরা নতুন একটা বাক্য এখানে যোগ করতে চাচ্ছি “বইমেলা এলে আমরা প্রচুর বই কিনি”। এর আগের উদাহরণে আমরা বাংলা দাড়ি ব্যাপারটা স্টপ ওয়ার্ডে ঢুকেছিলাম তবে এবার আমরা আমরা নতুন করে বলছি না। দেখি এবার আমাদের টোকেনাইজার কি করে? এখানে আমাদের নতুন কর্পাসে যতি চিহ্ন যোগ করলেও টোকেনাইজার আমাদের যতিচিহ্ন ফেলে দিয়েছে। সবচেয়ে মজার কথা হচ্ছে আমাদের কর্পাসে নতুন শব্দ যোগ হয়েছে নতুন সংখ্যা জোড়া ভ্যালু সহ। "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBqUseMdA_CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "    'আমি ভালবাসি বই পড়তে,',\n",
        "    'আমি ভালবাসি বই লিখতে!',\n",
        "    'বইমেলা এলে আমি প্রচুর বই কিনি'\n",
        "        ]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYCw5EXgCYj4",
        "colab_type": "text"
      },
      "source": [
        "আগের মতো \"ফিট অন টেক্সট\" করি।"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbeZpO4WCeXl",
        "colab_type": "code",
        "outputId": "055256cb-a5a0-4e7e-c357-df4ca4fdc380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'আমি': 1, 'বই': 2, 'ভালবাসি': 3, 'পড়তে': 4, 'লিখতে': 5, 'বইমেলা': 6, 'এলে': 7, 'প্রচুর': 8, 'কিনি': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtUdoaqBG8MJ",
        "colab_type": "text"
      },
      "source": [
        "আমাদের আগের বাক্যে চারটা করে শব্দ ছিল। এখন নতুন একটা বাক্য যোগ করলাম যেখানে ৬টা শব্দ যোগ করা হয়েছে। ইনডেক্সে নতুন বাক্যের ভেতরে ইউনিক শব্দগুলো বাদ দিয়ে বাকি শব্দগুলোকে নতুন করে জোড়া ‘কি-ভ্যালু’ দিয়ে দিয়েছে। এটা একটা নতুন ওয়ার্ড ভ্যালু ইনডেক্স যোগ করল কর্পাসে। দেখতে পাচ্ছেন তো ছবিতে?\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/raqueeb/nlp_bangla/master/assets/seq2.png)\n",
        "\n",
        "ছবি: নতুন ওয়ার্ড ইনডেক্স তৈরি হয়েছে কর্পাসে\n",
        "\n",
        "এখানে আমরা একটা বাক্যে বিভিন্ন শব্দ দিয়ে যে ডিকশনারি তৈরি করলাম সেটাকে কর্পাস হিসেবে ব্যবহার করছি। এতক্ষণ আমরা যা খেলেছি সেগুলো হচ্ছে শব্দকে এনকোড করা। এখন আমরা আমাদের বাক্যগুলোকে একটা লিস্টে ভাগ করব যেখানে টোকেনগুলোকে পাশাপাশি দেখা যাবে। এরপর টোকেনগুলোকে কিভাবে এদিক ওদিক করা যায় সেটা দেখবো আমরা।\n",
        "\n",
        "এখানে একটা মজার ধারণা নিয়ে আলাপ করি।\n",
        "\n",
        "## প্যাডিং, একই লেনথ এর বাক্য?\n",
        "\n",
        "আমরা এ পর্যন্ত যতগুলো বাক্য বলেছি তার মধ্যে দুটো বাক্য চারটা শব্দের আর একটা বাক্য ছয়টা শব্দের। আমরা যখন কোন নিউরাল নেটওয়ার্ক কিছু ফিট করতে চাই তখন সবকিছুই একি লেংথ বা সাইজ করে পাঠাই। মনে আছে আমরা ইমেজ নিয়ে কিভাবে কাজ করেছিলাম?  আমাদের ইনপুট লেয়ারে যখন প্রতিটা ইমেজ ফিড করছিলাম নিউরাল নেটওয়ার্ক সেখানে যদি ইমেজগুলো আলাদা সাইজের হতো সেগুলো কে প্রথমে আমরা রিসাইজ করে নিতাম  এক সাইজে। আমরা যখন টেক্সট নিয়ে কাজ করব তখন আমরা কখনোই বলতে পারব না একটা বাক্যে কতগুলো শব্দ হতে পারে এবং সেগুলোর সংখ্যা অনেকটাই অজানা থাকবে একটা নিউরাল নেটওয়ার্কের জন্য। \n",
        "\n",
        "গতবছর আমি scikit-learn দিয়ে ন্যাচারাল ল্যাংগুয়েজ প্রসেসিং ব্যাপারটা শুরু করলেও সেটাকে পরে বন্ধ করে টেন্সরফ্লো দিয়ে শুরু করেছিলাম।  তারপর পেছনে আর ফিরে তাকাতে হয়নি।  টেন্সরফ্লো ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং এর জন্য অনেকগুলো এপিআই তৈরি করে দিয়েছে যা সাধারণ পাইথন এবং scikit-learn দিয়ে ন্যাচারাল ল্যাঙ্গুয়েজ প্রসেসিং থেকে অনেক কষ্ট কমিয়ে নিয়ে এসেছে।  এর আগে আমরা এই জিনিসটার কিছুটা কাজ দেখেছি টেন্সরফ্লো দিয়ে।  আমরা যেহেতু সিকুয়েন্সের একটা লিস্ট ধরে কাজ শুরু করেছিলাম,  সেখানে বাক্যগুলোকে টোকেন দিয়ে এনকোড করে তার পাশাপাশি দরকারি কোড কোথায় কোথায় কিভাবে কাজ করছে সেটাও দেখেছি আগে। \n",
        "\n",
        "যেহেতু আমরা আরেকটা বাক্য যোগ করেছি আমাদের আগের বাক্যের লিস্ট এ,  সেখানে আগের দুটো বাক্যে চারটা শব্দ আর পরের বাক্যে আমরা ছয় শব্দ সহ নতুন বাক্য যোগ করেছিলাম। \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hq83aorjIS5",
        "colab_type": "text"
      },
      "source": [
        "## ৪টা বিভিন্ন লেনথের বাক্য দিয়ে কর্পাস\n",
        "\n",
        "এখন আমরা দেখতে চাইবো এরকম ভিন্ন ভিন্ন শব্দ সম্বলিত বাক্য গুলোকে কিভাবে আমরা নিউরাল নেটওয়ার্ক পাঠাবো?  আগের ইমেজের মত বলতে গেলে এখানেও আমরা একটা বাক্যে সর্বোচ্চ কতগুলো শব্দ হতে পারে তার পাশাপাশি ছোট শব্দ গুলোকে কিভাবে গোঁজামিল দিয়ে বড় শব্দ বানাবো সেটাই দেখব সামনে। \n",
        "\n",
        "ছোটবেলায় ক্যাডেট কলেজে যখন আমাদেরকে জুতা বানিয়ে দিত,  তখন আমরা ভাবতাম যাতে আমাদের জুতোগুলো একটু বড় থাকে।  কারণ  জুতো ছোট হলে পড়তে কষ্ট, তবে বড় হলে সমস্যা কম কারণ জুতোর ভেতরে কাপড়ের প্যাডিং দিয়ে বড় জুতা কে পড়া যায় সহজে।  জুতো বড় হলে সেখানে একটা মোজার জায়গায় দুটো পড়ে সেই কাজটা চালানো যেত সহজে। "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gjCYVmSZTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\n",
        "    'আমি ভালবাসি বই পড়তে,',\n",
        "    'আমি ভালবাসি বই লিখতে!',\n",
        "    'বইমেলা এলে আমি প্রচুর বই কিনি',\n",
        "    'এইবার বইমেলায় আমার সাথে তুমি কি যাবে?'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF00HP2MCe0z",
        "colab_type": "code",
        "outputId": "b6caa55c-9406-4aeb-a388-1325724ed31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(\"\\nওয়ার্ড ইনডেক্স = \" , word_index)\n",
        "print(\"\\nসিকোয়েন্স = \" , sequences)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ওয়ার্ড ইনডেক্স =  {'আমি': 1, 'বই': 2, 'ভালবাসি': 3, 'পড়তে': 4, 'লিখতে': 5, 'বইমেলা': 6, 'এলে': 7, 'প্রচুর': 8, 'কিনি': 9, 'এইবার': 10, 'বইমেলায়': 11, 'আমার': 12, 'সাথে': 13, 'তুমি': 14, 'কি': 15, 'যাবে': 16}\n",
            "\n",
            "সিকোয়েন্স =  [[1, 3, 2, 4], [1, 3, 2, 5], [6, 7, 1, 8, 2, 9], [10, 11, 12, 13, 14, 15, 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYD2KJfqU57N",
        "colab_type": "text"
      },
      "source": [
        "এই একই জিনিস ঘটবে আমাদের ছোট ছোট বাক্যের জন্য।  আমরা ধরে নিবো একটা বাক্য কত লম্বা হতে পারে।  এর পাশাপাশি আমরা ছোট ছোট বাক্যগুলোকে শূন্য দিয়ে প্যাডিং করে বড় বাক্য বানাবো যাতে  নিউরাল নেটওয়ার্ক সবসময় একই লম্বার বাক্য পায়। চলুন আমরা দেখে আসি আমাদের নতুন কোড,  যেখানে আমরা টোকেনাইজার ব্যবহার করব যাতে আমাদের বাক্যগুলোকে সিকোয়েন্সে পাল্টে দিতে পারে।  আমরা বলতে পারি একেকটা বাক্যের জন্য একেকটা সিকোয়েন্স,  এবং সেখানে প্রতিটা বাক্য একটা লিস্ট হিসেবে আউটপুটে আসবে। সেই লিস্টে শব্দগুলোকে ইন্টেজারে কনভার্ট হয়ে আসবে এখানে। টোকেনাইজারের texts_to_sequences মেথড আগের এবং পরের সব শব্দগুলোকে যোগ করেছে নতুন ওয়ার্ড এবং সংখ্যা ভ্যালু জোড়া ডিকশনারিতে। এখানে নতুন দুটো ৭ এবং ৮ শব্দের বাক্য যোগ করেছি কর্পাসে।\n",
        "\n",
        "![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/index2.png)\n",
        "\n",
        "চিত্র: ওয়ার্ড ইনডেক্স এবং সিকোয়েন্সের যোগসুত্র\n",
        "\n",
        "এবার আমরা চেষ্টা করব দ্বিতীয় পর্যায়ে যেতে। এখানে texts_to_sequences মেথড দিয়ে আমরা একটা বাক্য থেকে সংখ্যার একটা সিকুয়েন্স তৈরি করব যাতে একটা নিউরাল নেটওয়ার্ককে ঠিকমতো শেখাতে পারে। এখানে এমন একটা টুল ব্যবহার করব যাতে সে এই প্রসেসে সংখ্যার একটা সিকোয়েন্স এর লিস্ট তৈরি করতে পারে। আমাদের এই প্যাটার্ন স্পটিংটা খুব মজার।\n",
        "\n",
        "আমাদের নতুন কর্পাসে আগের যেই শব্দগুলো ছিল তার সাথে নতুন দুটো বাক্যের শুধুমাত্র নতুন শব্দগুলো যোগ হয়েছে পরে। আমাদের এখানে ওয়ার্ড ইন্ডেক্স এবং সিক্যুয়েন্স এই দুটোর মধ্যে সংযোগ সূত্র হিসেবে যে শব্দগুলো বারবার ব্যবহার করা হয়েছে সেগুলো চলে গেছে উপরে।  এর পাশাপাশি নতুন বাক্য থেকে যে শব্দগুলো নতুন এসেছে সেগুলো এসে যোগ হয়েছে ডিকশনারিতে নিচের দিকে।  এখানে একটা কথা বলে রাখা ভালো আমাদের চারপাশে আমরা যে শব্দ গুলোকে ব্যবহার করছি সেখানে মেশিন লার্নিং শুধুমাত্র এই কর্পাস এর ভেতরের শব্দ গুলোকে চিনে।  তার বাইরের কোনো শব্দ দিয়ে যদি আমরা টেস্ট করি তাহলে সেই শব্দগুলোকে সে চিনতে পারবে না।  এটাই তো স্বাভাবিক তাই না?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0mevgVaUhRn",
        "colab_type": "text"
      },
      "source": [
        "## কি হবে, যখন ওয়ার্ড ইনডেক্সে শব্দটা থাকবে না?\n",
        "\n",
        "আমরা যদি একটা নিউরাল নেটওয়ার্ক কে একটা নির্দিষ্ট কর পাশের টেক্সট মানে শব্দ এবং তার সেখান থেকে জেনারেটেড ওয়ার্ড ইন্ডেক্স  কে ট্রেইন করি তাহলে আমরা সেই ট্রেনিং মডেল থেকে একটা ইনফারেন্ট ব্যবহার করতে পারব।  এর অর্থ হচ্ছে আমাদেরকে সেই একই ওয়ার্ড ইন্ডেক্স এর উপর ইনফার করতে হবে যাকে আমরা সেই একই শব্দ দিয়ে ট্রেনিং করিয়েছিলাম।এর ব্যত্যয় হলে আমাদের কাজের কোন আউটপুট থাকবে না।  আমরা যে কর পাশ দিয়ে নিউরাল নেটওয়ার্ককে  ট্রেইন করাবো এর বাহিরে যদি কোন শব্দ আসে টেস্ট ডাটা সেটে তাহলে তো সে সেটার আউটকামস দিতে পারবে না। নিচে আমাদের নতুন দুটো বাক্য স্টেশন হিসেবে চালিয়ে দেখি।  আপনারা দেখতে পাচ্ছেন এখানে কিছু কিছু শব্দ আমাদের কর পাশে আছে তবে কিছু শব্দ আমাদের আগের কর্পাস এবং ওয়ার্ড ইনডেক্সে ছিলনা,  তাহলে এখন কি হবে?এখানে আমাদের ওয়ার্ড ইনডেক্স এবং সিক্যুয়েন্স দুটো দেখি।  আপনি বলুন এখানে কি কি মিসিং আছে অথবা কেন মিসিং আছে? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5At652ZlU-RQ",
        "colab_type": "code",
        "outputId": "7b65d3d5-7d60-422d-f474-cf728f7cdaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# আমরা নতুন কিছু শব্দ ব্যবহার করি যেটা আমাদের টোকেনাইজারকে ফিট করা হয়নি\n",
        "test_data = [\n",
        "    'আমি আসলেই ভালবাসি বই পড়তে',\n",
        "    'বইমেলায় এবার প্রচুর নতুন বই এসেছে!'\n",
        "]\n",
        "\n",
        "# texts_to_sequences কি বের করে দেখি\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"Test Sequence = \", test_seq)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Sequence =  [[1, 3, 2, 4], [11, 8, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05SWR3C7WSbs",
        "colab_type": "text"
      },
      "source": [
        "ওমা, কি হলো ব্যাপারটা? কিছু কিছু শব্দ হারিয়ে গেছে ওয়ার্ড ইনডেক্স এ না থাকার কারণে। কেন হলো এটা?\n",
        "\n",
        "![alt text](https://github.com/raqueeb/nlp_bangla/raw/master/assets/index3.png)\n",
        "\n",
        "এর অর্থ হচ্ছে \n",
        "\n",
        "১. প্রথম বাক্য: 'আমি ভালবাসি বই পড়তে', **আসলেই** মিসিং\n",
        "\n",
        "২. পরের বাক্যে: 'বইমেলায় প্রচুর বই', **এবার, নতুন, এসেছে** মিসিং।\n",
        "\n",
        "এটা থেকে বাঁচার উপায় কি? তারমানে একটা ভাষায় সব শব্দকে আনতে হবে আমাদের ওয়ার্ড ইনডেক্সে?\n",
        "\n",
        "কি বলে এটা?\n",
        "\n",
        "এটা সম্ভব?"
      ]
    }
  ]
}